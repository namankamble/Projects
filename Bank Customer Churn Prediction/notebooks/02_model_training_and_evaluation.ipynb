{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15093ba5-6ac9-47fb-849b-789cb6be8881",
   "metadata": {},
   "source": [
    "## ***Essential libraries:***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd15b78-0369-4614-8e67-ed07c35be478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a369596-e084-4a33-b9cb-598394e744f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore geography  gender  age  tenure    balance  numofproducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   hascrcard  isactivemember  estimatedsalary  exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('../data/clean_data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9218899-4088-4bf9-8543-ca094c198252",
   "metadata": {},
   "source": [
    "***\n",
    "#### ***Encoding Categorical Variables***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a351375-9f80-42a4-a4fe-8f9950b22962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_data = pd.get_dummies(data, columns=['geography', 'gender'], drop_first=True)\n",
    "\n",
    "bool_cols = new_data.select_dtypes(include='bool').columns\n",
    "bool_cols = new_data.select_dtypes(include='bool').columns\n",
    "\n",
    "new_data[bool_cols] = new_data[bool_cols].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731dfb9-9bff-49b3-955f-aeba74d23752",
   "metadata": {},
   "source": [
    "***\n",
    "### ***Data Splitting (Train/Test Sets)***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1823582-d596-4608-968e-5b5478c95036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = new_data.drop(columns='exited',axis=1)\n",
    "y = new_data['exited']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c17fcf58-8a91-4e87-95a8-bc1ecb398bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 11), (2000, 11), (8000,), (2000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979e449-be44-4505-adfc-229ce8beef30",
   "metadata": {},
   "source": [
    "***\n",
    "#### ***Feature Scaling***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c35e54f1-8e4b-44af-854a-4d6f4dd3d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193765d-8e85-4595-a889-a5e8df1d9561",
   "metadata": {},
   "source": [
    "***\n",
    "#### ***Apply SMOTE to training set***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45d2492c-8ed3-4e4f-8d76-b58c7aafba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e8230f8-e733-4240-afce-073e3202353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6365, 1: 6365}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273047e-b311-438a-8daa-5aed55827c73",
   "metadata": {},
   "source": [
    "***\n",
    "#### ***Modeling & Evaluation***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5bb5cd7-69bc-44d9-8f23-0d22042af583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6365, number of negative: 6365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1685\n",
      "[LightGBM] [Info] Number of data points in the train set: 12730, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"xgboost\": xgb.XGBClassifier(),\n",
    "    \"lightgbm\": lgb.LGBMClassifier(),\n",
    "    \"catboost\": cb.CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1 Score\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c7fc776-a804-4926-90c0-6936abc60b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.594816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.554726</td>\n",
       "      <td>0.593085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.598901</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.569191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.8265</td>\n",
       "      <td>0.569975</td>\n",
       "      <td>0.557214</td>\n",
       "      <td>0.563522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.8265</td>\n",
       "      <td>0.558887</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.600690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.483370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.351804</td>\n",
       "      <td>0.679104</td>\n",
       "      <td>0.463497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1 Score\n",
       "catboost               0.8515   0.658610  0.542289  0.594816\n",
       "lightgbm               0.8470   0.637143  0.554726  0.593085\n",
       "xgboost                0.8350   0.598901  0.542289  0.569191\n",
       "Random Forest          0.8265   0.569975  0.557214  0.563522\n",
       "Gradient Boosting      0.8265   0.558887  0.649254  0.600690\n",
       "Decision Tree          0.7670   0.436000  0.542289  0.483370\n",
       "Logistic Regression    0.6840   0.351804  0.679104  0.463497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.8265</td>\n",
       "      <td>0.558887</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.600690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.594816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.554726</td>\n",
       "      <td>0.593085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.598901</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.569191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.8265</td>\n",
       "      <td>0.569975</td>\n",
       "      <td>0.557214</td>\n",
       "      <td>0.563522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.483370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.351804</td>\n",
       "      <td>0.679104</td>\n",
       "      <td>0.463497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1 Score\n",
       "Gradient Boosting      0.8265   0.558887  0.649254  0.600690\n",
       "catboost               0.8515   0.658610  0.542289  0.594816\n",
       "lightgbm               0.8470   0.637143  0.554726  0.593085\n",
       "xgboost                0.8350   0.598901  0.542289  0.569191\n",
       "Random Forest          0.8265   0.569975  0.557214  0.563522\n",
       "Decision Tree          0.7670   0.436000  0.542289  0.483370\n",
       "Logistic Regression    0.6840   0.351804  0.679104  0.463497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Results DataFrame\n",
    "model_results = pd.DataFrame(results).T\n",
    "display(model_results.sort_values(by='Accuracy', ascending=False))\n",
    "print(47*'-')\n",
    "display(model_results.sort_values(by='F1 Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240e076-4f44-4409-9b32-9b556b86b09b",
   "metadata": {},
   "source": [
    "#### ***Insights:***\n",
    "- ***`Best F1 Score:`*** Gradient Boosting (0.6007) – Even though it doesn’t have the highest accuracy, its balance between precision and recall gives it the best F1 score, ideal for imbalanced datasets.\n",
    "\n",
    "- ***`Best Accuracy:`*** CatBoost (0.8515) – Performs well overall and is likely the best option if accuracy is your primary metric.\n",
    "\n",
    "- Logistic Regression shows the weakest performance — typical for linear models on complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415b302-8ab2-475a-a9b7-a8d6283b073b",
   "metadata": {},
   "source": [
    "***\n",
    "### ***Tuning***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48a88395-fe96-4b40-b777-ff8ab180629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6365, number of negative: 6365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1685\n",
      "[LightGBM] [Info] Number of data points in the train set: 12730, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.679104</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.679104</td>\n",
       "      <td>0.575949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>0.495512</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.5756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>{'depth': 3, 'iterations': 50, 'learning_rate'...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.567901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.547744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.468013</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.558233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.351804</td>\n",
       "      <td>0.679104</td>\n",
       "      <td>0.463497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Best Params  \\\n",
       "Gradient Boosting    {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "LightGBM             {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "XGBoost              {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "CatBoost             {'depth': 3, 'iterations': 50, 'learning_rate'...   \n",
       "Decision Tree                 {'max_depth': 5, 'min_samples_split': 2}   \n",
       "Random Forest                     {'max_depth': 5, 'n_estimators': 50}   \n",
       "Logistic Regression                                           {'C': 1}   \n",
       "\n",
       "                    Accuracy Precision    Recall  F1 Score  \n",
       "Gradient Boosting     0.8005  0.502762  0.679104  0.577778  \n",
       "LightGBM               0.799       0.5  0.679104  0.575949  \n",
       "XGBoost               0.7965  0.495512  0.686567    0.5756  \n",
       "CatBoost                0.79  0.484211  0.686567  0.567901  \n",
       "Decision Tree         0.7845  0.473684  0.649254  0.547744  \n",
       "Random Forest           0.78  0.468013  0.691542  0.558233  \n",
       "Logistic Regression    0.684  0.351804  0.679104  0.463497  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'model': LogisticRegression(max_iter=500),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [3, 5],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'model': RandomForestClassifier(n_jobs=-1),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'model': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3]\n",
    "        }\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'model': lgb.LGBMClassifier(n_jobs=-1),\n",
    "        'params': {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3]\n",
    "        }\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'model': cb.CatBoostClassifier(verbose=0),\n",
    "        'params': {\n",
    "            'iterations': [50],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'depth': [3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, mp in param_grids.items():\n",
    "    grid = GridSearchCV(mp['model'], mp['params'], cv=3, scoring='f1', n_jobs=-1)\n",
    "    grid.fit(x_train_resampled, y_train_resampled)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(x_test_scaled)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid.best_params_,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "model_results = pd.DataFrame(results).T\n",
    "display(model_results.sort_values(by='Accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b751116-0d98-4a6f-a528-cc075dc90f34",
   "metadata": {},
   "source": [
    "#### ***Key Insights:***\n",
    "Overall Performance Drop After Tuning:\n",
    "- `Most models slightly dropped in accuracy and F1 Score after hyperparameter tuning`, likely due to reduced complexity (e.g., lower max_depth) or constraints added to avoid overfitting.\n",
    "\n",
    "- `Gradient Boosting Still Performs Well:` Even after tuning, Gradient Boosting maintains a strong F1 Score (0.5778) and good general performance — making it a reliable choice, especially for imbalanced classification tasks.\n",
    "\n",
    "- C`atBoost Dropped in Accuracy:` Accuracy went down from 0.8515 to 0.790 — hyperparameters like fewer iterations or depth may have caused underfitting.\n",
    "\n",
    "- `Logistic Regression Remained the Same:` No noticeable improvement — expected for linear models on non-linear data.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3f656-ca67-41dd-be1a-63e1fbb16fad",
   "metadata": {},
   "source": [
    "# ***Final Recommendation***\n",
    "*After comparing the performance of various classification models before and after hyperparameter tuning, the following recommendations are proposed:*\n",
    "\n",
    "***$->$ Best Overall Model (Balanced Performance)***       \n",
    "`Gradient Boosting (Tuned)`\n",
    "- Best Params: learning_rate=0.1, max_depth=3, n_estimators=100\n",
    "- F1 Score: 0.5778\n",
    "- Recall: 0.6791\n",
    "- Stable and reliable performance across all metrics\n",
    "- Recommended when both precision and recall are important (e.g., churn, fraud detection)\n",
    "\n",
    "***$->$ Best Model (Baseline - Highest Accuracy)***             \n",
    "`CatBoost (Baseline)`\n",
    "- Accuracy: 0.8515\n",
    "- Slight trade-off in recall and F1 Score\n",
    "- Fast and requires minimal preprocessing (handles categorical features internally)\n",
    "- Recommended for scenarios where accuracy matters more than recall\n",
    "- Best Lightweight Model (Simple & Interpretable)\n",
    "\n",
    "`Decision Tree (Tuned)`\n",
    "- Best Params: max_depth=5, min_samples_split=2\n",
    "- Improved F1 Score after tuning\n",
    "- Easy to visualize and explain\n",
    "- Recommended for quick baseline testing or when explainability is a priority\n",
    "- Models Not Recommended for This Dataset\n",
    "\n",
    "`Logistic Regression`\n",
    "- Consistently underperformed on all metrics\n",
    "- Suitable only for linearly separable data\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a2a85-216b-4766-9b12-13e04f459812",
   "metadata": {},
   "source": [
    "### ***final model:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ebc0787-0749-46f1-ad41-1365740cd0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy (CatBoost): 0.8515\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cbc = cb.CatBoostClassifier(verbose=0)  # Suppress training output\n",
    "cbc.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = cbc.predict(x_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Accuracy (CatBoost): {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85b5999b-69d0-4276-b84c-f18484dc0045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/final_catboost_model.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(cbc, '../models/final_catboost_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
